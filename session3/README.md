# Session 3: Data Presentation

## Content
- [Overview](#overview)
- [Session Outline](#session-outline)
- [Lab Exercises](#lab-exercises)
- [Homework](#homework)

## Overview
- Wednesday, 22nd August, 2018
- Time: 09:30 – 13:00

#### Objectives
- [ ] Introduce learners to data verification and cleaning as a process for ensuring data quality and reproducibility in the data process.
- [ ] Introduce learners to the structure and importance of a **tidy dataset**.
- [ ] Explore techniques and tools for data verification and cleaning using a spreadsheet tool(Excel, Libre Office etc).
- [ ] Setup and use Open Refine as a tool for simple and advanced data verification and cleaning.

#### Outcomes
- [ ] Each learner can verify and clean data using Open Refine.
- [ ] Each learner can identify and fix design issues with a visualisation.
- [ ] Each learner can create a visualisation using open source tools (spreadsheets, Fusion Tables, Plotly, Infogram, Tableau, DataWrapper)
- [ ] Each learner can transform a basic quality visualisation into a publication-level visualisation using a graphical visual editor.



## Session Outline
Duration | Activity | Resources | Responsible
--------- | ---------------| ----------| ----------
09:30 – 09:45 | Review of Previous Sessions & Feedback on Homework Exercises | [The School of Data Pipeline](https://schoolofdata.org/methodology/); [Calculating Averages and Percentage Changes](/labs/data_fundamentals_lab5_calculating_averages_and_percentages_changes.pdf); [Exploring Data in Larger Datasets](/labs/data_fundamentals_lab6_exploring_data_in_larger_datasets.pdf); [Exploring Data with Pivot Tables](/labs/data_fundamentals_lab7_exploring_data_with_pivot_table) | All
09:45 – 10:45 | Open Refine Lab Exercise | [Enipedia OpenRefine Tutorial](http://enipedia.tudelft.nl/wiki/OpenRefine_Tutorial) | Fellows
10:45 – 11:00 | Break | Restroom | All
11:00 – 11:30 | Introduction to Data Visualisation Design | [Visual Design Slides Slides](https://docs.google.com/presentation/d/1zxnFSYOmS0w1H5dDjW_0L2kJnHVvBhI1QcagJbQVPW4/edit?usp=sharing) | Facilitator
11:30 - 12:00 | Data Visualisation Exercise | Exercise Slides | Fellows
12:00 - 12:30 | Visualisation Tools Demo | Google Sheets, Plotly, Infogram, Tableau | Facilitator
12:30 – 13:00 | Group Mini Project Progress | Outline | Fellows

## Some Data Verification Questions
-  Source
    - Who or what is the source of the original data?
    -  When was the data published?
    - Is there an official contact or use policy for this data?
    - How was the data collected: methodology?
- Meta Data
  - Are variables or column names explained including with appropriate units?
  - What assumptions were made from data collection to publishing stages?
- Values
  - Does the data have the expected number of rows or observations?
  - Does the data have the expected number of columns or variables?
  - Is the distribution of values what is expected?
  - Is there any outliers?
  - Are there any missing values in the data?
  - Do you obtain the expected summary statistics on a given column?
- Ethics/Privacy
  - Does the data contain any individually identifiable data?
  - Are there any ethical concerns about the data?



## Lab Exercises
### Lab 1: Data Verification (30 mins)
1. Identify a dataset of interest in machine-readable format (.csv, .tsv, .xlsx, .xls etc)
2. Verify your dataset using the questions above, making notes to share with a partner later.


### Lab 2: Data Cleaning with Open Refine (30 mins)
1. Read and practice the concepts from [Data Carpentry Open Refine Lesson](http://www.datacarpentry.org/OpenRefine-ecology-lesson/00-getting-started/) with a partner. Ensure that you try out the expressions/commands in Open Refine. Make any notes of concepts you have questions on for discuss in the next section.
2. Discuss any questions you have with the facilitator as you progress.

### Lab 3: R Data Pipeline (Define, Find, Get, Verify, Clean) (45 mins)
1. Select a question or interest. Be as specific as possible. Eg: Regions in Tanzania near the coast have a high incidence of water-borne diseases.
2. Follow the data pipeline to produce a clean or tidy dataset ready for analysis.
