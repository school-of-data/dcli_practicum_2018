# Session 1: Practicum Overview, Quiz Review & Data Pipeline

## Overview
 - Wednesday, 8th August, 2018
 - Time: 09:30 – 13:00

#### Objectives
- [ ] Provide overview of practicum including content, structure and goals
- [ ] Review the pre-training assessment quiz
- [ ] Introduce learners to the data pipeline as a framework for working with data.
- [ ] Define team project or question to explore during practicum.
- [ ] Assign readings and task for session 2.

#### Outcomes
- [ ] Each learner can explain the data pipeline from their own context to another learner.
- [ ] Each learner has successfully installed a spreadsheet software on their laptops.
- [ ] Each learner can begin using R to create objects, install and load libraries, and use functions to perform calculations and analysis.

## Session Plan

Duration | Activity | Resources | Responsible
------------- | ---------- | -------- | ---------
09:30 - 09:50 | Introduction | [DCLI Practicum Introduction Slides](https://docs.google.com/presentation/d/1XYAwdjPSdEg8wrYhzduVBqShTgG-Ct5trn6OKv3hJtQ/edit?usp=sharing) | Facilitator
09:50 – 10:00 | Data pipeline | [School of Data pipeline](https://schoolofdata.org/methodology/) | All
10:00 – 10:20 | Quiz Review |[Pre-training Assessment Quiz](https://docs.google.com/document/d/1Vr-GdhrQaoL1chzRxckSPDGgxDFqYGQDP7amAT7_7LE/edit?usp=sharing) | Fellows
10:20 – 11:00 | Finding Data: Google Advanced Search, Google Alerts, Data Portals | [Defining, Finding And Getting Data Manual](/manuals/defining_finding_and_getting_data.pdf) | Facilitator
11:00 - 11:15 | Break | Restrooms | All
11:15 – 11:45 | Getting Data: PDF and Web Scraping | [Defining, Finding And Getting Data Manual](/manuals/defining_finding_and_getting_data.pdf) | Fellows
11:45 – 12:45 | Lab Exercises: PDF and Web Scraping | [PDF Scraping Lab](/labs/data_fundamentals_lab_scraping_data_from_pdfs.pdf), [Web Scraping Lab](/labs/data_fundamentals_lab_scraping_data_from_the_web.pdf) | Fellows
12:45 – 13:00 | Review and Closing | Learning plan | Facilitator

## Homework
- **Complete the [Data Carpentry Intro to R lesson](http://www.datacarpentry.org/R-ecology-lesson/01-intro-to-r.html):** this is to make you familiar with the R syntax necessary to work with data in future sessions. Try out each of the syntax and concepts in RStudio and make notes of anything you have questions about.
- **Complete PDF Scraping Reading and Exercise:** please read this [School of Data PDF Scraping tutorial](https://schoolofdata.org/extracting-data-from-pdfs/)  and extract the [example pdf](https://schoolofdata.org/files/2015/09/sample-data-for-scraping.pdf) into **machine-readable** format by the start of session 2. You will have to download and install [Tabula](http://tabula.technology/) to complete this exercise.
- **Install [Google Chrome Browser](https://www.google.com/chrome/browser/desktop/index.html):** we will be doing web scraping with a couple of Google Chrome extensions in session 2. Please ensure that you have the Google Chrome browser installed at the beginning of the session.

## Resources
- [The School of Data Pipeline](https://schoolofdata.org/methodology/)
- 
